/**
 * Subtitles Service - Fetch and parse YouTube captions
 * Based on yt-dlp _extract_captions (line 2683-2750)
 */

export interface SubtitleTrack {
    id: string;
    label: string;
    language: string;
    languageCode: string;
    url: string;
    isAutoGenerated: boolean;
}

export interface SubtitleCue {
    start: number; // seconds
    end: number;
    text: string;
}

class SubtitlesServiceClass {
    /**
     * Fetch available subtitle tracks for a YouTube video
     */
    async getYouTubeSubtitles(videoId: string): Promise<SubtitleTrack[]> {
        const tracks: SubtitleTrack[] = [];

        try {
            // Request player data with captions
            const requestBody = {
                context: {
                    client: {
                        clientName: 'ANDROID',
                        clientVersion: '19.09.37',
                        androidSdkVersion: 30,
                    },
                },
                videoId: videoId,
            };

            const response = await fetch('https://www.youtube.com/youtubei/v1/player?prettyPrint=false', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(requestBody),
            });

            if (!response.ok) return tracks;

            const data = await response.json();
            const captions = data?.captions?.playerCaptionsTracklistRenderer?.captionTracks;

            if (!captions) return tracks;

            for (const caption of captions) {
                tracks.push({
                    id: caption.vssId || caption.languageCode,
                    label: caption.name?.simpleText || caption.languageCode,
                    language: caption.name?.simpleText || caption.languageCode,
                    languageCode: caption.languageCode,
                    url: caption.baseUrl,
                    isAutoGenerated: caption.kind === 'asr',
                });
            }

            console.log(`[Subtitles] Found ${tracks.length} tracks for ${videoId}`);
        } catch (error) {
            console.error('[Subtitles] Failed to fetch:', error);
        }

        return tracks;
    }

    /**
     * Fetch and parse subtitle content (VTT/XML)
     */
    async loadSubtitleTrack(track: SubtitleTrack): Promise<SubtitleCue[]> {
        const cues: SubtitleCue[] = [];

        try {
            // Request VTT format
            const url = `${track.url}&fmt=vtt`;
            const response = await fetch(url);

            if (!response.ok) return cues;

            const text = await response.text();
            return this.parseVTT(text);
        } catch (error) {
            console.error('[Subtitles] Failed to load track:', error);
        }

        return cues;
    }

    /**
     * Parse WebVTT format
     */
    parseVTT(content: string): SubtitleCue[] {
        const cues: SubtitleCue[] = [];
        const lines = content.split('\n');

        let currentCue: Partial<SubtitleCue> = {};
        let inCue = false;
        let textLines: string[] = [];

        for (const line of lines) {
            const trimmedLine = line.trim();

            // Skip WEBVTT header and empty lines
            if (trimmedLine.startsWith('WEBVTT') || trimmedLine.startsWith('NOTE')) {
                continue;
            }

            // Timestamp line
            const timestampMatch = trimmedLine.match(/(\d{2}:\d{2}:\d{2}\.\d{3}|\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3}|\d{2}:\d{2}\.\d{3})/);
            if (timestampMatch) {
                // Save previous cue if exists
                if (inCue && textLines.length > 0) {
                    currentCue.text = textLines.join('\n');
                    cues.push(currentCue as SubtitleCue);
                }

                // Start new cue
                currentCue = {
                    start: this.parseTimestamp(timestampMatch[1]),
                    end: this.parseTimestamp(timestampMatch[2]),
                };
                textLines = [];
                inCue = true;
                continue;
            }

            // Empty line ends cue
            if (trimmedLine === '') {
                if (inCue && textLines.length > 0) {
                    currentCue.text = textLines.join('\n');
                    cues.push(currentCue as SubtitleCue);
                    currentCue = {};
                    textLines = [];
                    inCue = false;
                }
                continue;
            }

            // Text line
            if (inCue) {
                // Remove VTT styling tags
                const cleanText = trimmedLine.replace(/<[^>]+>/g, '');
                if (cleanText) {
                    textLines.push(cleanText);
                }
            }
        }

        // Don't forget last cue
        if (inCue && textLines.length > 0) {
            currentCue.text = textLines.join('\n');
            cues.push(currentCue as SubtitleCue);
        }

        return cues;
    }

    /**
     * Parse timestamp to seconds
     */
    private parseTimestamp(timestamp: string): number {
        const parts = timestamp.split(':');
        if (parts.length === 2) {
            // MM:SS.mmm
            const [minutes, seconds] = parts;
            return parseInt(minutes, 10) * 60 + parseFloat(seconds);
        } else if (parts.length === 3) {
            // HH:MM:SS.mmm
            const [hours, minutes, seconds] = parts;
            return parseInt(hours, 10) * 3600 + parseInt(minutes, 10) * 60 + parseFloat(seconds);
        }
        return 0;
    }

    /**
     * Get current cue for given time
     */
    getCurrentCue(cues: SubtitleCue[], currentTime: number): SubtitleCue | null {
        for (const cue of cues) {
            if (currentTime >= cue.start && currentTime <= cue.end) {
                return cue;
            }
        }
        return null;
    }
}

export const SubtitlesService = new SubtitlesServiceClass();
